{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FractalNet Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89745b9740954808b282450d085470b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e837bb7f5eac42d3983413008b5dd3c7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86b36b460a0a4a58aa0d1865c14fd6f7",
              "IPY_MODEL_f0196c86fe2a48ac915e5fdb9150e6b3"
            ]
          }
        },
        "e837bb7f5eac42d3983413008b5dd3c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86b36b460a0a4a58aa0d1865c14fd6f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_892a05d913054487a70a603297c39ade",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 50210,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50210,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f7feef5c8304ae0bba71ec3f23cb564"
          }
        },
        "f0196c86fe2a48ac915e5fdb9150e6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4677c0b61f75403c908bb95ff05808ea",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 50210/50210 [01:11&lt;00:00, 706.77it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93a13278505b43f18762f41af4e47ef5"
          }
        },
        "892a05d913054487a70a603297c39ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f7feef5c8304ae0bba71ec3f23cb564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4677c0b61f75403c908bb95ff05808ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93a13278505b43f18762f41af4e47ef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2af2f886f0b04030b15ebe9b2c87201e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_543f405d3d3d457ab0ab416cc088b846",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_319136a7595c48f980d511f571f9f6ef",
              "IPY_MODEL_ac01b83bcba34232ab6926ff917fafc2"
            ]
          }
        },
        "543f405d3d3d457ab0ab416cc088b846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "319136a7595c48f980d511f571f9f6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c9fe6a9b5e9e4a7185fb53332befe4dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 50210,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50210,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db132ec7c8304588909f80c15c5ca9f3"
          }
        },
        "ac01b83bcba34232ab6926ff917fafc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1dc7a9d8bd6e429f926c18d6c6a66a48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 50210/50210 [01:38&lt;00:00, 507.81it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05e9bdd1ad5e4c80a549b82405e2bf1a"
          }
        },
        "c9fe6a9b5e9e4a7185fb53332befe4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db132ec7c8304588909f80c15c5ca9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1dc7a9d8bd6e429f926c18d6c6a66a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05e9bdd1ad5e4c80a549b82405e2bf1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "376ab883207a4686bc906b498f4047d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_82e52c3330af463caed3eb8bb2068b5f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e415bc532e7449dacf7e12026b75035",
              "IPY_MODEL_333a48ab973f45aa9b27dab50759b6b3"
            ]
          }
        },
        "82e52c3330af463caed3eb8bb2068b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e415bc532e7449dacf7e12026b75035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d0dbaae4ea84eedb1e4587c40148ccc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 50210,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50210,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57cb07ca893846de8037a9f4376d37e1"
          }
        },
        "333a48ab973f45aa9b27dab50759b6b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a9e52477d9e84d05975033c283ff10d1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 50210/50210 [01:12&lt;00:00, 696.63it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a39124215c34ab4ae23251a85f9dd05"
          }
        },
        "2d0dbaae4ea84eedb1e4587c40148ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57cb07ca893846de8037a9f4376d37e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a9e52477d9e84d05975033c283ff10d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a39124215c34ab4ae23251a85f9dd05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fbb0d3c3151b42b1b6de36961adc29a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_64f9ba04e9a047dd867ce93c274054a3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ff6a28d3c0f14c1db5ccf033c4e2b9de",
              "IPY_MODEL_5d59d485241b4494bc90f7c17a4f76ea"
            ]
          }
        },
        "64f9ba04e9a047dd867ce93c274054a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ff6a28d3c0f14c1db5ccf033c4e2b9de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c1542258e21c4f9daf11e70f1f335e7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 50210,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50210,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f9cc019ac38454a90b256e7720aefa9"
          }
        },
        "5d59d485241b4494bc90f7c17a4f76ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01342d9c3b9b469fbd55c9d1c344d83b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 50210/50210 [01:12&lt;00:00, 694.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_967da0420a784fd28d24f77f579632b1"
          }
        },
        "c1542258e21c4f9daf11e70f1f335e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f9cc019ac38454a90b256e7720aefa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01342d9c3b9b469fbd55c9d1c344d83b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "967da0420a784fd28d24f77f579632b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5LD-03u5eOo",
        "colab_type": "code",
        "outputId": "c981cc55-f207-4943-ec2b-349325bd58e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm46DGqxEJte",
        "colab_type": "code",
        "outputId": "cab336c9-4981-47b5-87a8-73f2bd10d54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm.auto import tqdm\n",
        "from glob import glob\n",
        "import time, gc\n",
        "import cv2\n",
        "from tensorflow import keras\n",
        "import matplotlib.image as mpimg\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.models import clone_model\n",
        "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import albumentations as A"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK0uZpcURKVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN = ['drive/My Drive/Neural NotWork/Data/train_image_data_0.parquet',\n",
        "         'drive/My Drive/Neural NotWork/Data/train_image_data_1.parquet',\n",
        "         'drive/My Drive/Neural NotWork/Data/train_image_data_2.parquet',\n",
        "         'drive/My Drive/Neural NotWork/Data/train_image_data_3.parquet']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOMb5cF_Xjru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEST =  ['drive/My Drive/Neural NotWork/Data/test_image_data_0.parquet',\n",
        "         'drive/My Drive/Neural NotWork/Data/test_image_data_1.parquet',\n",
        "         'drive/My Drive/Neural NotWork/Data/test_image_data_2.parquet',\n",
        "         'drive/My Drive/Neural NotWork/Data/test_image_data_3.parquet']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTMpqysCRKb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_ = pd.read_csv('drive/My Drive/Neural NotWork/Data/train.csv')\n",
        "sample_sub_df = pd.read_csv('drive/My Drive/Neural NotWork/Data/sample_submission.csv')\n",
        "\n",
        "# not really useful, just for human understanding\n",
        "class_map_df = pd.read_csv('drive/My Drive/Neural NotWork/Data/class_map.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StCSjHNnYKDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEIGHT = 137\n",
        "WIDTH = 236"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggW8kp4hZZFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize(df, size=64, need_progress_bar=True):\n",
        "    resized = {}\n",
        "    resize_size=56\n",
        "    angle=0\n",
        "    if need_progress_bar:\n",
        "        for i in tqdm(range(df.shape[0])):\n",
        "            #image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size),None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
        "            image=df.loc[df.index[i]].values.reshape(137,236)\n",
        "            #Centering\n",
        "            image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "            matrix = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "            image = cv2.warpAffine(image, matrix, image.shape[1::-1], flags=cv2.INTER_LINEAR,\n",
        "                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
        "            #Scaling\n",
        "            matrix = cv2.getRotationMatrix2D(image_center, 0, 1.0)\n",
        "            image = cv2.warpAffine(image, matrix, image.shape[1::-1], flags=cv2.INTER_LINEAR,\n",
        "                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
        "            # #Removing Blur\n",
        "            # aug = A.GaussianBlur(p=1.0)\n",
        "            # image = aug(image=image)['image']\n",
        "            # #Noise Removing\n",
        "            # augNoise=A.MultiplicativeNoise(p=1.0)\n",
        "            # image = augNoise(image=image)['image']\n",
        "            # #Removing Distortion\n",
        "            # augDist=A.ElasticTransform(sigma=50, alpha=1, alpha_affine=10, p=1.0)\n",
        "            # image = augDist(image=image)['image']\n",
        "            #Brightness\n",
        "            augBright=A.RandomBrightnessContrast(p=1.0)\n",
        "            image = augBright(image=image)['image']\n",
        "            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
        "\n",
        "            idx = 0 \n",
        "            ls_xmin = []\n",
        "            ls_ymin = []\n",
        "            ls_xmax = []\n",
        "            ls_ymax = []\n",
        "            for cnt in contours:\n",
        "                idx += 1\n",
        "                x,y,w,h = cv2.boundingRect(cnt)\n",
        "                ls_xmin.append(x)\n",
        "                ls_ymin.append(y)\n",
        "                ls_xmax.append(x + w)\n",
        "                ls_ymax.append(y + h)\n",
        "            xmin = min(ls_xmin)\n",
        "            ymin = min(ls_ymin)\n",
        "            xmax = max(ls_xmax)\n",
        "            ymax = max(ls_ymax)\n",
        "\n",
        "            roi = image[ymin:ymax,xmin:xmax]\n",
        "            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n",
        "            #image=affine_image(image)\n",
        "            #image= crop_resize(image)\n",
        "            #image = cv2.resize(image,(size,size),interpolation=cv2.INTER_AREA)\n",
        "            #image=resize_image(image,(64,64))\n",
        "            #image = cv2.resize(image,(size,size),interpolation=cv2.INTER_AREA)\n",
        "            #gaussian_3 = cv2.GaussianBlur(image, (5,5), cv2.BORDER_DEFAULT) #unblur\n",
        "            #image = cv2.addWeighted(image, 1.5, gaussian_3, -0.5, 0, image)\n",
        "            #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
        "            #image = cv2.filter2D(image, -1, kernel)\n",
        "            #ret,image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "            resized[df.index[i]] = resized_roi.reshape(-1)\n",
        "    else:\n",
        "        for i in range(df.shape[0]):\n",
        "            #image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size),None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
        "            image=df.loc[df.index[i]].values.reshape(137,236)\n",
        "            image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
        "            matrix = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
        "            image = cv2.warpAffine(image, matrix, image.shape[1::-1], flags=cv2.INTER_LINEAR,\n",
        "                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
        "            matrix = cv2.getRotationMatrix2D(image_center, 0, 1.0)\n",
        "            image = cv2.warpAffine(image, matrix, image.shape[1::-1], flags=cv2.INTER_LINEAR,\n",
        "                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
        "            #Removing Blur\n",
        "            #aug = A.GaussianBlur(p=1.0)\n",
        "            #image = aug(image=image)['image']\n",
        "            #Noise Removing\n",
        "            #augNoise=A.MultiplicativeNoise(p=1.0)\n",
        "            #image = augNoise(image=image)['image']\n",
        "            #Removing Distortion\n",
        "            #augDist=A.ElasticTransform(sigma=50, alpha=1, alpha_affine=10, p=1.0)\n",
        "            #image = augDist(image=image)['image']\n",
        "            #Brightness\n",
        "            augBright=A.RandomBrightnessContrast(p=1.0)\n",
        "            image = augBright(image=image)['image']\n",
        "            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
        "\n",
        "            idx = 0 \n",
        "            ls_xmin = []\n",
        "            ls_ymin = []\n",
        "            ls_xmax = []\n",
        "            ls_ymax = []\n",
        "            for cnt in contours:\n",
        "                idx += 1\n",
        "                x,y,w,h = cv2.boundingRect(cnt)\n",
        "                ls_xmin.append(x)\n",
        "                ls_ymin.append(y)\n",
        "                ls_xmax.append(x + w)\n",
        "                ls_ymax.append(y + h)\n",
        "            xmin = min(ls_xmin)\n",
        "            ymin = min(ls_ymin)\n",
        "            xmax = max(ls_xmax)\n",
        "            ymax = max(ls_ymax)\n",
        "\n",
        "            roi = image[ymin:ymax,xmin:xmax]\n",
        "            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n",
        "            #image=affine_image(image)\n",
        "            #image= crop_resize(image)\n",
        "            #image = cv2.resize(image,(size,size),interpolation=cv2.INTER_AREA)\n",
        "            #image=resize_image(image,(64,64))\n",
        "            #image = cv2.resize(image,(size,size),interpolation=cv2.INTER_AREA)\n",
        "            #gaussian_3 = cv2.GaussianBlur(image, (5,5), cv2.BORDER_DEFAULT) #unblur\n",
        "            #image = cv2.addWeighted(image, 1.5, gaussian_3, -0.5, 0, image)\n",
        "            #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n",
        "            #image = cv2.filter2D(image, -1, kernel)\n",
        "            #ret,image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "            resized[df.index[i]] = resized_roi.reshape(-1)\n",
        "    resized = pd.DataFrame(resized).T\n",
        "    return resized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTsIPdK-gFLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dummies(df):\n",
        "    cols = []\n",
        "    for col in df:\n",
        "        cols.append(pd.get_dummies(df[col].astype(str)))\n",
        "    return pd.concat(cols, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UekCaULFGuTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import (\n",
        "    Input,\n",
        "    BatchNormalization,\n",
        "    Activation, Dense, Dropout,\n",
        "    Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        ")\n",
        "from keras.models import Model\n",
        "from keras.engine import Layer\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def theano_multinomial(n, pvals, seed):\n",
        "    rng = RandomStreams(seed)\n",
        "    return rng.multinomial(n=n, pvals=pvals, dtype='float32')\n",
        "\n",
        "def tensorflow_categorical(count, seed):\n",
        "    assert count > 0\n",
        "    arr = [1.] + [.0 for _ in range(count-1)]\n",
        "    return tf.random_shuffle(arr, seed)\n",
        "\n",
        "# Returns a random array [x0, x1, ...xn] where one is 1 and the others\n",
        "# are 0. Ex: [0, 0, 1, 0].\n",
        "def rand_one_in_array(count, seed=None):\n",
        "    if seed is None:\n",
        "        seed = np.random.randint(1, 10e6)\n",
        "    return tensorflow_categorical(count=count, seed=seed)\n",
        "\n",
        "class JoinLayer(Layer):\n",
        "    '''\n",
        "    This layer will behave as Merge(mode='ave') during testing but\n",
        "    during training it will randomly select between using local or\n",
        "    global droppath and apply the average of the paths alive after\n",
        "    aplying the drops.\n",
        "    - Global: use the random shared tensor to select the paths.\n",
        "    - Local: sample a random tensor to select the paths.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, drop_p, is_global, global_path, force_path, **kwargs):\n",
        "        #print \"init\"\n",
        "        self.p = 1. - drop_p\n",
        "        self.is_global = is_global\n",
        "        self.global_path = global_path\n",
        "        self.uses_learning_phase = True\n",
        "        self.force_path = force_path\n",
        "        super(JoinLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        # For serialization with 'custom_objects'\n",
        "        config = super().get_config()\n",
        "        config['idx_init'] = self.idx_init\n",
        "        config['idx_end'] = self.idx_end\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        #print(\"build\")\n",
        "        self.average_shape = list(input_shape[0])[1:]\n",
        "\n",
        "    def _random_arr(self, count, p):\n",
        "        return K.random_binomial((count,), p=p)\n",
        "\n",
        "    def _arr_with_one(self, count):\n",
        "        return rand_one_in_array(count=count)\n",
        "\n",
        "    def _gen_local_drops(self, count, p):\n",
        "        # Create a local droppath with at least one path\n",
        "        arr = self._random_arr(count, p)\n",
        "        drops = K.switch(\n",
        "            K.any(arr),\n",
        "            arr,\n",
        "            self._arr_with_one(count)\n",
        "        )\n",
        "        return drops\n",
        "\n",
        "    def _gen_global_path(self, count):\n",
        "        return self.global_path[:count]\n",
        "\n",
        "    def _drop_path(self, inputs):\n",
        "        count = len(inputs)\n",
        "        drops = K.switch(\n",
        "            self.is_global,\n",
        "            self._gen_global_path(count),\n",
        "            self._gen_local_drops(count, self.p)\n",
        "        )\n",
        "        ave = K.zeros(shape=self.average_shape)\n",
        "        for i in range(0, count):\n",
        "            ave += inputs[i] * drops[i]\n",
        "        sum = K.sum(drops)\n",
        "        # Check that the sum is not 0 (global droppath can make it\n",
        "        # 0) to avoid divByZero\n",
        "        ave = K.switch(\n",
        "            K.not_equal(sum, 0.),\n",
        "            ave/sum,\n",
        "            ave)\n",
        "        return ave\n",
        "\n",
        "    def _ave(self, inputs):\n",
        "        ave = inputs[0]\n",
        "        for input in inputs[1:]:\n",
        "            ave += input\n",
        "        ave /= len(inputs)\n",
        "        return ave\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        #print(\"call\")\n",
        "        if self.force_path:\n",
        "            output = self._drop_path(inputs)\n",
        "        else:\n",
        "            output = K.in_train_phase(self._drop_path(inputs), self._ave(inputs))\n",
        "        return output\n",
        "\n",
        "    def get_output_shape_for(self, input_shape):\n",
        "        #print(\"get_output_shape_for\", input_shape)\n",
        "        return input_shape[0]\n",
        "\n",
        "class JoinLayerGen:\n",
        "    '''\n",
        "    JoinLayerGen will initialize seeds for both global droppath\n",
        "    switch and global droppout path.\n",
        "    These seeds will be used to create the random tensors that the\n",
        "    children layers will use to know if they must use global droppout\n",
        "    and which path to take in case it is.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, width, global_p=0.5, deepest=False):\n",
        "        self.global_p = global_p\n",
        "        self.width = width\n",
        "        self.switch_seed = np.random.randint(1, 10e6)\n",
        "        self.path_seed = np.random.randint(1, 10e6)\n",
        "        self.deepest = deepest\n",
        "        if deepest:\n",
        "            self.is_global = K.variable(1.)\n",
        "            self.path_array = K.variable([1.] + [.0 for _ in range(width-1)])\n",
        "        else:\n",
        "            self.is_global = self._build_global_switch()\n",
        "            self.path_array = self._build_global_path_arr()\n",
        "\n",
        "    def _build_global_path_arr(self):\n",
        "        # The path the block will take when using global droppath\n",
        "        return rand_one_in_array(seed=self.path_seed, count=self.width)\n",
        "\n",
        "    def _build_global_switch(self):\n",
        "        # A randomly sampled tensor that will signal if the batch\n",
        "        # should use global or local droppath\n",
        "        return K.equal(K.random_binomial((), p=self.global_p, seed=self.switch_seed), 1.)\n",
        "\n",
        "    def get_join_layer(self, drop_p):\n",
        "        global_switch = self.is_global\n",
        "        global_path = self.path_array\n",
        "        return JoinLayer(drop_p=drop_p, is_global=global_switch, global_path=global_path, force_path=self.deepest)\n",
        "\n",
        "def fractal_conv(filter, nb_row, nb_col, dropout=None):\n",
        "    def f(prev):\n",
        "        conv = prev\n",
        "        conv = Convolution2D(filter, nb_row=nb_col, nb_col=nb_col, init='he_normal', border_mode='same')(conv)\n",
        "        if dropout:\n",
        "            conv = Dropout(dropout)(conv)\n",
        "        conv = BatchNormalization(mode=0, axis= -1)(conv)\n",
        "        conv = Activation('relu')(conv)\n",
        "        return conv\n",
        "    return f\n",
        "\n",
        "# XXX_ It's not clear when to apply Dropout, the paper cited\n",
        "# (arXiv:1511.07289) uses it in the last layer of each stack but in\n",
        "# the code gustav published it is in each convolution block so I'm\n",
        "# copying it.\n",
        "def fractal_block(join_gen, c, filter, nb_col, nb_row, drop_p, dropout=None):\n",
        "    def f(z):\n",
        "        columns = [[z] for _ in range(c)]\n",
        "        last_row = 2**(c-1) - 1\n",
        "        for row in range(2**(c-1)):\n",
        "            t_row = []\n",
        "            for col in range(c):\n",
        "                prop = 2**(col)\n",
        "                # Add blocks\n",
        "                if (row+1) % prop == 0:\n",
        "                    t_col = columns[col]\n",
        "                    t_col.append(fractal_conv(filter=filter,\n",
        "                                              nb_col=nb_col,\n",
        "                                              nb_row=nb_row,\n",
        "                                              dropout=dropout)(t_col[-1]))\n",
        "                    t_row.append(col)\n",
        "            # Merge (if needed)\n",
        "            if len(t_row) > 1:\n",
        "                merging = [columns[x][-1] for x in t_row]\n",
        "                merged  = join_gen.get_join_layer(drop_p=drop_p)(merging)\n",
        "                for i in t_row:\n",
        "                    columns[i].append(merged)\n",
        "        return columns[0][-1]\n",
        "    return f\n",
        "\n",
        "def fractal_net(b, c, conv, drop_path, global_p=0.5, dropout=None, deepest=False):\n",
        "    '''\n",
        "    Return a function that builds the Fractal part of the network\n",
        "    respecting keras functional model.\n",
        "    When deepest is set, we build the entire network but set droppath\n",
        "    to global and the Join masks to [1., 0... 0.] so only the deepest\n",
        "    column is always taken.\n",
        "    We don't add the softmax layer here nor build the model.\n",
        "    '''\n",
        "    def f(z):\n",
        "        output = z\n",
        "        # Initialize a JoinLayerGen that will be used to derive the\n",
        "        # JoinLayers that share the same global droppath\n",
        "        join_gen = JoinLayerGen(width=c, global_p=global_p, deepest=deepest)\n",
        "        for i in range(b):\n",
        "            (filter, nb_col, nb_row) = conv[i]\n",
        "            dropout_i = dropout[i] if dropout else None\n",
        "            output = fractal_block(join_gen=join_gen,\n",
        "                                   c=c, filter=filter,\n",
        "                                   nb_col=nb_col,\n",
        "                                   nb_row=nb_row,\n",
        "                                   drop_p=drop_path,\n",
        "                                   dropout=dropout_i)(output)\n",
        "            output = MaxPooling2D(pool_size=(2,2), strides=(2,2))(output)\n",
        "        return output\n",
        "    return f"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaaIpckmhGyq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE=56\n",
        "N_CHANNELS=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KK2JvqAG_mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD, RMSprop, Adam, Nadam\n",
        "import tensorflow as tf\n",
        "def build_network(deepest=False):\n",
        "    dropout = [0., 0.1, 0.2, 0.3, 0.4]\n",
        "    conv = [(64, 3, 3), (128, 3, 3), (256, 3, 3), (512, 3, 3), (512, 2, 2)]\n",
        "    input= Input(shape = (IMG_SIZE, IMG_SIZE, 1))\n",
        "    output = fractal_net(\n",
        "        c=3, b=5, conv=conv,\n",
        "        drop_path=0.15, dropout=dropout,\n",
        "        deepest=deepest)(input)\n",
        "    output = Flatten()(output)\n",
        "    \n",
        "    head_root = Dense(168, init='he_normal', activation = 'softmax', name = 'roots')(output)\n",
        "    head_vowel = Dense(11, init='he_normal', activation = 'softmax', name = 'vowels')(output)\n",
        "    head_consonant = Dense(7, init='he_normal', activation = 'softmax', name = 'consonants')(output)\n",
        "    model = Model(inputs=input, outputs=[head_root, head_vowel, head_consonant])\n",
        "    #optimizer = SGD(lr=LEARN_START, momentum=MOMENTUM)\n",
        "    #optimizer = SGD(lr=LEARN_START, momentum=MOMENTUM, nesterov=True)\n",
        "    #optimizer = Adam()\n",
        "    # optimizer = SGD(lr=0.02, momentum=0.9)\n",
        "    model.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySrOjKEjMDn7",
        "colab_type": "code",
        "outputId": "a3c3cff3-487e-486f-b843-1c1a2a0a3bb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "model = build_network(deepest=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:147: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:150: UserWarning: Update your `BatchNormalization` call to the Keras 2 API: `BatchNormalization(axis=-1)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4452: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4454: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:147: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:147: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:147: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:147: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (2, 2), padding=\"same\", kernel_initializer=\"he_normal\")`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(168, activation=\"softmax\", name=\"roots\", kernel_initializer=\"he_normal\")`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(11, activation=\"softmax\", name=\"vowels\", kernel_initializer=\"he_normal\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(7, activation=\"softmax\", name=\"consonants\", kernel_initializer=\"he_normal\")`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWSbxnzxgiZ3",
        "colab_type": "code",
        "outputId": "33401a4a-7675-4cef-ce73-a31d5bf99ba2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 56, 56, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 56, 56, 64)   640         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 56, 56, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 56, 56, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 56, 56, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 56, 56, 64)   640         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 56, 56, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 56, 56, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 56, 56, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 56, 56, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_1 (JoinLayer)        [(None, 56, 56, 64), 0           activation_2[0][0]               \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 56, 56, 64)   36928       join_layer_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 56, 56, 64)   256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 56, 56, 64)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 56, 56, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 56, 56, 64)   36928       join_layer_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 56, 56, 64)   640         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 56, 56, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 56, 56, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 56, 56, 64)   256         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 56, 56, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 56, 56, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 56, 56, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_2 (JoinLayer)        [(None, 56, 56, 64), 0           activation_5[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 28, 28, 64)   0           join_layer_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 28, 28, 128)  73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 28, 28, 128)  0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 28, 28, 128)  512         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 28, 28, 128)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 128)  147584      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 28, 28, 128)  73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 28, 28, 128)  0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 28, 28, 128)  0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 28, 28, 128)  512         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 28, 28, 128)  512         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 28, 28, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_3 (JoinLayer)        [(None, 28, 28, 128) 0           activation_9[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 128)  147584      join_layer_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 28, 28, 128)  0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 28, 28, 128)  512         dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 28, 28, 128)  147584      join_layer_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 28, 28, 128)  73856       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 28, 28, 128)  0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 28, 28, 128)  0           conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 28, 28, 128)  0           conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 28, 128)  512         dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 128)  512         dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_4 (JoinLayer)        [(None, 28, 28, 128) 0           activation_12[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 128)  0           join_layer_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 14, 14, 256)  295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 14, 14, 256)  0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 14, 14, 256)  1024        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 14, 14, 256)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 14, 14, 256)  590080      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 14, 14, 256)  295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 14, 14, 256)  0           conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 14, 14, 256)  0           conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 14, 14, 256)  1024        dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 14, 14, 256)  1024        dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 14, 14, 256)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 14, 14, 256)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_5 (JoinLayer)        [(None, 14, 14, 256) 0           activation_16[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 256)  590080      join_layer_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 14, 14, 256)  0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 14, 14, 256)  1024        dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 14, 14, 256)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 14, 14, 256)  590080      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 14, 14, 256)  590080      join_layer_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 14, 14, 256)  295168      max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 14, 14, 256)  0           conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 14, 14, 256)  0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 14, 14, 256)  0           conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 14, 14, 256)  1024        dropout_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 14, 14, 256)  1024        dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 14, 14, 256)  1024        dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 14, 14, 256)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 14, 14, 256)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 14, 14, 256)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_6 (JoinLayer)        [(None, 14, 14, 256) 0           activation_19[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 7, 7, 256)    0           join_layer_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 7, 7, 512)    1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 7, 7, 512)    0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 7, 7, 512)    2048        dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 7, 7, 512)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 7, 7, 512)    2359808     activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 7, 7, 512)    1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 7, 7, 512)    0           conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_17 (Dropout)            (None, 7, 7, 512)    0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 7, 7, 512)    2048        dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 7, 7, 512)    2048        dropout_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 7, 7, 512)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 7, 7, 512)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_7 (JoinLayer)        [(None, 7, 7, 512),  0           activation_23[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 7, 7, 512)    2359808     join_layer_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_18 (Dropout)            (None, 7, 7, 512)    0           conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 7, 7, 512)    2048        dropout_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 7, 7, 512)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 512)    2359808     activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 7, 7, 512)    2359808     join_layer_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 7, 7, 512)    1180160     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_19 (Dropout)            (None, 7, 7, 512)    0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 7, 7, 512)    0           conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_21 (Dropout)            (None, 7, 7, 512)    0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 512)    2048        dropout_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 7, 7, 512)    2048        dropout_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 7, 7, 512)    2048        dropout_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 512)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 7, 7, 512)    0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 7, 7, 512)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_8 (JoinLayer)        [(None, 7, 7, 512),  0           activation_26[0][0]              \n",
            "                                                                 activation_27[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 3, 3, 512)    0           join_layer_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 3, 3, 512)    1049088     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_22 (Dropout)            (None, 3, 3, 512)    0           conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 3, 3, 512)    2048        dropout_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 512)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 3, 3, 512)    1049088     activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 3, 3, 512)    1049088     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 3, 3, 512)    0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_24 (Dropout)            (None, 3, 3, 512)    0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 3, 3, 512)    2048        dropout_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 3, 3, 512)    2048        dropout_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 512)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 3, 3, 512)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_9 (JoinLayer)        [(None, 3, 3, 512),  0           activation_30[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 3, 3, 512)    1049088     join_layer_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_25 (Dropout)            (None, 3, 3, 512)    0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 3, 3, 512)    2048        dropout_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 512)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 3, 3, 512)    1049088     activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 3, 3, 512)    1049088     join_layer_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 3, 3, 512)    1049088     max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_26 (Dropout)            (None, 3, 3, 512)    0           conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_27 (Dropout)            (None, 3, 3, 512)    0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_28 (Dropout)            (None, 3, 3, 512)    0           conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 3, 3, 512)    2048        dropout_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 3, 3, 512)    2048        dropout_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 3, 3, 512)    2048        dropout_28[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 512)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 512)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 3, 3, 512)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "join_layer_10 (JoinLayer)       [(None, 3, 3, 512),  0           activation_33[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 512)    0           join_layer_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 512)          0           max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "roots (Dense)                   (None, 168)          86184       flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "vowels (Dense)                  (None, 11)           5643        flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "consonants (Dense)              (None, 7)            3591        flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 24,667,322\n",
            "Trainable params: 24,646,714\n",
            "Non-trainable params: 20,608\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0jpwUPrk_55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate_reduction_root = ReduceLROnPlateau(monitor='roots_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1,\n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00002)\n",
        "learning_rate_reduction_vowel = ReduceLROnPlateau(monitor='vowels_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1,\n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00002)\n",
        "learning_rate_reduction_consonant = ReduceLROnPlateau(monitor='consonants_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1,\n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00002)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0n7xbe1leCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#decreased batch size\n",
        "batch_size = 256\n",
        "epochs = 30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z66tIucle2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n",
        "\n",
        "    def flow(self,\n",
        "             x,\n",
        "             y=None,\n",
        "             batch_size=32,\n",
        "             shuffle=True,\n",
        "             sample_weight=None,\n",
        "             seed=None,\n",
        "             save_to_dir=None,\n",
        "             save_prefix='',\n",
        "             save_format='png',\n",
        "             subset=None):\n",
        "\n",
        "        targets = None\n",
        "        target_lengths = {}\n",
        "        ordered_outputs = []\n",
        "        for output, target in y.items():\n",
        "            if targets is None:\n",
        "                targets = target\n",
        "            else:\n",
        "                targets = np.concatenate((targets, target), axis=1)\n",
        "            target_lengths[output] = target.shape[1]\n",
        "            ordered_outputs.append(output)\n",
        "\n",
        "\n",
        "        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n",
        "                                         shuffle=shuffle):\n",
        "            target_dict = {}\n",
        "            i = 0\n",
        "            for output in ordered_outputs:\n",
        "                target_length = target_lengths[output]\n",
        "                target_dict[output] = flowy[:, i: i + target_length]\n",
        "                i += target_length\n",
        "\n",
        "            yield flowx, target_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOtUH_7yChc1",
        "colab_type": "code",
        "outputId": "9f40a68e-8748-4b17-bddf-11ba61110178",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## run this before retrain modified model \n",
        "keras.backend.backend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tensorflow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzV5jxwDloyv",
        "colab_type": "code",
        "outputId": "1d09d1ea-d129-4f4d-cd0e-548da696af76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "89745b9740954808b282450d085470b3",
            "e837bb7f5eac42d3983413008b5dd3c7",
            "86b36b460a0a4a58aa0d1865c14fd6f7",
            "f0196c86fe2a48ac915e5fdb9150e6b3",
            "892a05d913054487a70a603297c39ade",
            "4f7feef5c8304ae0bba71ec3f23cb564",
            "4677c0b61f75403c908bb95ff05808ea",
            "93a13278505b43f18762f41af4e47ef5",
            "2af2f886f0b04030b15ebe9b2c87201e",
            "543f405d3d3d457ab0ab416cc088b846",
            "319136a7595c48f980d511f571f9f6ef",
            "ac01b83bcba34232ab6926ff917fafc2",
            "c9fe6a9b5e9e4a7185fb53332befe4dd",
            "db132ec7c8304588909f80c15c5ca9f3",
            "1dc7a9d8bd6e429f926c18d6c6a66a48",
            "05e9bdd1ad5e4c80a549b82405e2bf1a",
            "376ab883207a4686bc906b498f4047d5",
            "82e52c3330af463caed3eb8bb2068b5f",
            "0e415bc532e7449dacf7e12026b75035",
            "333a48ab973f45aa9b27dab50759b6b3",
            "2d0dbaae4ea84eedb1e4587c40148ccc",
            "57cb07ca893846de8037a9f4376d37e1",
            "a9e52477d9e84d05975033c283ff10d1",
            "8a39124215c34ab4ae23251a85f9dd05",
            "fbb0d3c3151b42b1b6de36961adc29a1",
            "64f9ba04e9a047dd867ce93c274054a3",
            "ff6a28d3c0f14c1db5ccf033c4e2b9de",
            "5d59d485241b4494bc90f7c17a4f76ea",
            "c1542258e21c4f9daf11e70f1f335e7a",
            "8f9cc019ac38454a90b256e7720aefa9",
            "01342d9c3b9b469fbd55c9d1c344d83b",
            "967da0420a784fd28d24f77f579632b1"
          ]
        }
      },
      "source": [
        "histories = []\n",
        "for i in range(4):\n",
        "    train_df = pd.merge(pd.read_parquet(f'drive/My Drive/Neural NotWork/Data/train_image_data_{i}.parquet'), train_df_, on='image_id').drop(['image_id'], axis=1)\n",
        "    # Visualize few samples of current training dataset\n",
        "    # fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(16, 8))\n",
        "    # count=0\n",
        "    # for row in ax:\n",
        "    #     for col in row:\n",
        "    #         col.imshow(resize(train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1).iloc[[count]], need_progress_bar=False).values.reshape(IMG_SIZE, IMG_SIZE))\n",
        "    #         count += 1\n",
        "    # plt.show()\n",
        "    \n",
        "    X_train = train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic', 'grapheme'], axis=1)\n",
        "    X_train = resize(X_train)/255\n",
        "    \n",
        "    # CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images\n",
        "    X_train = X_train.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n",
        "    \n",
        "    Y_train_root = pd.get_dummies(train_df['grapheme_root']).values\n",
        "    Y_train_vowel = pd.get_dummies(train_df['vowel_diacritic']).values\n",
        "    Y_train_consonant = pd.get_dummies(train_df['consonant_diacritic']).values\n",
        "\n",
        "    print(f'Training images: {X_train.shape}')\n",
        "    print(f'Training labels root: {Y_train_root.shape}')\n",
        "    print(f'Training labels vowel: {Y_train_vowel.shape}')\n",
        "    print(f'Training labels consonants: {Y_train_consonant.shape}')\n",
        "\n",
        "    # Divide the data into training and validation set\n",
        "    x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = train_test_split(X_train, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.08, random_state=124)\n",
        "    del train_df\n",
        "    del X_train\n",
        "    del Y_train_root, Y_train_vowel, Y_train_consonant\n",
        "\n",
        "    # Data augmentation for creating more training data\n",
        "    datagen = MultiOutputDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.15, # Randomly zoom image \n",
        "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "    # This will just calculate parameters required to augment the given data. This won't perform any augmentations\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model\n",
        "    history = model.fit_generator(datagen.flow(x_train, {'roots': y_train_root, 'vowels': y_train_vowel, 'consonants': y_train_consonant}, batch_size=batch_size),\n",
        "                              epochs = epochs, validation_data = (x_test, [y_test_root, y_test_vowel, y_test_consonant]), \n",
        "                              steps_per_epoch=x_train.shape[0] // batch_size, \n",
        "                              callbacks=[learning_rate_reduction_root, learning_rate_reduction_vowel, learning_rate_reduction_consonant])\n",
        "\n",
        "    histories.append(history)\n",
        "    \n",
        "    # Delete to reduce memory usage\n",
        "    del x_train\n",
        "    del x_test\n",
        "    del y_train_root\n",
        "    del y_test_root\n",
        "    del y_train_vowel\n",
        "    del y_test_vowel\n",
        "    del y_train_consonant\n",
        "    del y_test_consonant\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89745b9740954808b282450d085470b3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training images: (50210, 56, 56, 1)\n",
            "Training labels root: (50210, 168)\n",
            "Training labels vowel: (50210, 11)\n",
            "Training labels consonants: (50210, 7)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/30\n",
            "180/180 [==============================] - 123s 685ms/step - loss: 8.5066 - roots_loss: 4.9190 - vowels_loss: 2.2159 - consonants_loss: 1.3716 - roots_acc: 0.0263 - vowels_acc: 0.2059 - consonants_acc: 0.6132 - val_loss: 8.7056 - val_roots_loss: 4.8569 - val_vowels_loss: 2.2456 - val_consonants_loss: 1.6030 - val_roots_acc: 0.0256 - val_vowels_acc: 0.2074 - val_consonants_acc: 0.1424\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1379: RuntimeWarning: Reduce LR on plateau conditioned on metric `roots_accuracy` which is not available. Available metrics are: val_loss,val_roots_loss,val_vowels_loss,val_consonants_loss,val_roots_acc,val_vowels_acc,val_consonants_acc,loss,roots_loss,vowels_loss,consonants_loss,roots_acc,vowels_acc,consonants_acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1379: RuntimeWarning: Reduce LR on plateau conditioned on metric `vowels_accuracy` which is not available. Available metrics are: val_loss,val_roots_loss,val_vowels_loss,val_consonants_loss,val_roots_acc,val_vowels_acc,val_consonants_acc,loss,roots_loss,vowels_loss,consonants_loss,roots_acc,vowels_acc,consonants_acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1379: RuntimeWarning: Reduce LR on plateau conditioned on metric `consonants_accuracy` which is not available. Available metrics are: val_loss,val_roots_loss,val_vowels_loss,val_consonants_loss,val_roots_acc,val_vowels_acc,val_consonants_acc,loss,roots_loss,vowels_loss,consonants_loss,roots_acc,vowels_acc,consonants_acc,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/30\n",
            "180/180 [==============================] - 110s 609ms/step - loss: 7.5535 - roots_loss: 4.6753 - vowels_loss: 1.7361 - consonants_loss: 1.1421 - roots_acc: 0.0309 - vowels_acc: 0.3757 - consonants_acc: 0.6232 - val_loss: 8.4500 - val_roots_loss: 4.7166 - val_vowels_loss: 2.3256 - val_consonants_loss: 1.4078 - val_roots_acc: 0.0289 - val_vowels_acc: 0.2452 - val_consonants_acc: 0.4663\n",
            "Epoch 3/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 6.7854 - roots_loss: 4.5079 - vowels_loss: 1.2645 - consonants_loss: 1.0130 - roots_acc: 0.0408 - vowels_acc: 0.5554 - consonants_acc: 0.6493 - val_loss: 7.0685 - val_roots_loss: 4.4300 - val_vowels_loss: 1.5202 - val_consonants_loss: 1.1184 - val_roots_acc: 0.0388 - val_vowels_acc: 0.4272 - val_consonants_acc: 0.6077\n",
            "Epoch 4/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 5.8244 - roots_loss: 4.0660 - vowels_loss: 0.9459 - consonants_loss: 0.8125 - roots_acc: 0.0725 - vowels_acc: 0.6838 - consonants_acc: 0.7186 - val_loss: 7.0480 - val_roots_loss: 4.2209 - val_vowels_loss: 1.9600 - val_consonants_loss: 0.8671 - val_roots_acc: 0.0602 - val_vowels_acc: 0.3244 - val_consonants_acc: 0.6901\n",
            "Epoch 5/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 4.7211 - roots_loss: 3.3281 - vowels_loss: 0.7686 - consonants_loss: 0.6244 - roots_acc: 0.1623 - vowels_acc: 0.7470 - consonants_acc: 0.7830 - val_loss: 5.5759 - val_roots_loss: 3.3113 - val_vowels_loss: 1.4193 - val_consonants_loss: 0.8453 - val_roots_acc: 0.1820 - val_vowels_acc: 0.5278 - val_consonants_acc: 0.6846\n",
            "Epoch 6/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 3.4057 - roots_loss: 2.3362 - vowels_loss: 0.6237 - consonants_loss: 0.4457 - roots_acc: 0.3505 - vowels_acc: 0.7980 - consonants_acc: 0.8540 - val_loss: 3.3276 - val_roots_loss: 2.3147 - val_vowels_loss: 0.6228 - val_consonants_loss: 0.3901 - val_roots_acc: 0.3562 - val_vowels_acc: 0.7782 - val_consonants_acc: 0.8730\n",
            "Epoch 7/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 2.5058 - roots_loss: 1.6480 - vowels_loss: 0.5087 - consonants_loss: 0.3491 - roots_acc: 0.5253 - vowels_acc: 0.8366 - consonants_acc: 0.8863 - val_loss: 2.5787 - val_roots_loss: 1.5847 - val_vowels_loss: 0.6749 - val_consonants_loss: 0.3190 - val_roots_acc: 0.5405 - val_vowels_acc: 0.7590 - val_consonants_acc: 0.9054\n",
            "Epoch 8/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 1.9715 - roots_loss: 1.2347 - vowels_loss: 0.4381 - consonants_loss: 0.2988 - roots_acc: 0.6440 - vowels_acc: 0.8602 - consonants_acc: 0.9047 - val_loss: 1.9814 - val_roots_loss: 1.3242 - val_vowels_loss: 0.3404 - val_consonants_loss: 0.3168 - val_roots_acc: 0.6236 - val_vowels_acc: 0.8875 - val_consonants_acc: 0.8900\n",
            "Epoch 9/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 1.6505 - roots_loss: 1.0025 - vowels_loss: 0.3838 - consonants_loss: 0.2642 - roots_acc: 0.7126 - vowels_acc: 0.8804 - consonants_acc: 0.9159 - val_loss: 1.7814 - val_roots_loss: 1.2284 - val_vowels_loss: 0.3291 - val_consonants_loss: 0.2239 - val_roots_acc: 0.6445 - val_vowels_acc: 0.9047 - val_consonants_acc: 0.9315\n",
            "Epoch 10/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 1.4482 - roots_loss: 0.8481 - vowels_loss: 0.3569 - consonants_loss: 0.2432 - roots_acc: 0.7549 - vowels_acc: 0.8903 - consonants_acc: 0.9223 - val_loss: 1.4255 - val_roots_loss: 0.8815 - val_vowels_loss: 0.2391 - val_consonants_loss: 0.3050 - val_roots_acc: 0.7441 - val_vowels_acc: 0.9385 - val_consonants_acc: 0.8959\n",
            "Epoch 11/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 1.2889 - roots_loss: 0.7497 - vowels_loss: 0.3162 - consonants_loss: 0.2230 - roots_acc: 0.7808 - vowels_acc: 0.9043 - consonants_acc: 0.9298 - val_loss: 1.2520 - val_roots_loss: 0.7866 - val_vowels_loss: 0.2906 - val_consonants_loss: 0.1748 - val_roots_acc: 0.7690 - val_vowels_acc: 0.9119 - val_consonants_acc: 0.9485\n",
            "Epoch 12/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 1.1676 - roots_loss: 0.6673 - vowels_loss: 0.2953 - consonants_loss: 0.2050 - roots_acc: 0.8066 - vowels_acc: 0.9113 - consonants_acc: 0.9372 - val_loss: 1.2569 - val_roots_loss: 0.8227 - val_vowels_loss: 0.2505 - val_consonants_loss: 0.1838 - val_roots_acc: 0.7590 - val_vowels_acc: 0.9310 - val_consonants_acc: 0.9455\n",
            "Epoch 13/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 1.0705 - roots_loss: 0.6071 - vowels_loss: 0.2729 - consonants_loss: 0.1905 - roots_acc: 0.8234 - vowels_acc: 0.9173 - consonants_acc: 0.9418 - val_loss: 0.9489 - val_roots_loss: 0.5522 - val_vowels_loss: 0.2365 - val_consonants_loss: 0.1603 - val_roots_acc: 0.8434 - val_vowels_acc: 0.9293 - val_consonants_acc: 0.9529\n",
            "Epoch 14/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 1.0187 - roots_loss: 0.5720 - vowels_loss: 0.2620 - consonants_loss: 0.1847 - roots_acc: 0.8344 - vowels_acc: 0.9206 - consonants_acc: 0.9425 - val_loss: 1.0479 - val_roots_loss: 0.6646 - val_vowels_loss: 0.2235 - val_consonants_loss: 0.1598 - val_roots_acc: 0.8178 - val_vowels_acc: 0.9350 - val_consonants_acc: 0.9589\n",
            "Epoch 15/30\n",
            "180/180 [==============================] - 109s 605ms/step - loss: 0.9529 - roots_loss: 0.5254 - vowels_loss: 0.2545 - consonants_loss: 0.1730 - roots_acc: 0.8464 - vowels_acc: 0.9252 - consonants_acc: 0.9473 - val_loss: 0.8170 - val_roots_loss: 0.5113 - val_vowels_loss: 0.1762 - val_consonants_loss: 0.1295 - val_roots_acc: 0.8521 - val_vowels_acc: 0.9517 - val_consonants_acc: 0.9627\n",
            "Epoch 16/30\n",
            "180/180 [==============================] - 109s 605ms/step - loss: 0.8975 - roots_loss: 0.4914 - vowels_loss: 0.2424 - consonants_loss: 0.1637 - roots_acc: 0.8565 - vowels_acc: 0.9276 - consonants_acc: 0.9499 - val_loss: 0.8104 - val_roots_loss: 0.5265 - val_vowels_loss: 0.1617 - val_consonants_loss: 0.1222 - val_roots_acc: 0.8504 - val_vowels_acc: 0.9554 - val_consonants_acc: 0.9644\n",
            "Epoch 17/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.8603 - roots_loss: 0.4705 - vowels_loss: 0.2269 - consonants_loss: 0.1629 - roots_acc: 0.8621 - vowels_acc: 0.9321 - consonants_acc: 0.9494 - val_loss: 0.7168 - val_roots_loss: 0.4196 - val_vowels_loss: 0.1660 - val_consonants_loss: 0.1311 - val_roots_acc: 0.8832 - val_vowels_acc: 0.9549 - val_consonants_acc: 0.9604\n",
            "Epoch 18/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.8153 - roots_loss: 0.4388 - vowels_loss: 0.2219 - consonants_loss: 0.1547 - roots_acc: 0.8705 - vowels_acc: 0.9336 - consonants_acc: 0.9524 - val_loss: 0.8850 - val_roots_loss: 0.5470 - val_vowels_loss: 0.2017 - val_consonants_loss: 0.1363 - val_roots_acc: 0.8459 - val_vowels_acc: 0.9475 - val_consonants_acc: 0.9577\n",
            "Epoch 19/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.7903 - roots_loss: 0.4277 - vowels_loss: 0.2188 - consonants_loss: 0.1438 - roots_acc: 0.8767 - vowels_acc: 0.9361 - consonants_acc: 0.9549 - val_loss: 0.7799 - val_roots_loss: 0.4986 - val_vowels_loss: 0.1572 - val_consonants_loss: 0.1241 - val_roots_acc: 0.8601 - val_vowels_acc: 0.9582 - val_consonants_acc: 0.9619\n",
            "Epoch 20/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.7657 - roots_loss: 0.4061 - vowels_loss: 0.2110 - consonants_loss: 0.1486 - roots_acc: 0.8797 - vowels_acc: 0.9373 - consonants_acc: 0.9560 - val_loss: 0.6981 - val_roots_loss: 0.4333 - val_vowels_loss: 0.1486 - val_consonants_loss: 0.1163 - val_roots_acc: 0.8765 - val_vowels_acc: 0.9612 - val_consonants_acc: 0.9666\n",
            "Epoch 21/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.7410 - roots_loss: 0.3929 - vowels_loss: 0.2075 - consonants_loss: 0.1406 - roots_acc: 0.8831 - vowels_acc: 0.9378 - consonants_acc: 0.9568 - val_loss: 0.7276 - val_roots_loss: 0.4348 - val_vowels_loss: 0.1749 - val_consonants_loss: 0.1180 - val_roots_acc: 0.8748 - val_vowels_acc: 0.9529 - val_consonants_acc: 0.9654\n",
            "Epoch 22/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.7021 - roots_loss: 0.3749 - vowels_loss: 0.1930 - consonants_loss: 0.1342 - roots_acc: 0.8887 - vowels_acc: 0.9414 - consonants_acc: 0.9601 - val_loss: 0.7829 - val_roots_loss: 0.4614 - val_vowels_loss: 0.1940 - val_consonants_loss: 0.1276 - val_roots_acc: 0.8658 - val_vowels_acc: 0.9450 - val_consonants_acc: 0.9632\n",
            "Epoch 23/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.6829 - roots_loss: 0.3596 - vowels_loss: 0.1902 - consonants_loss: 0.1331 - roots_acc: 0.8931 - vowels_acc: 0.9429 - consonants_acc: 0.9590 - val_loss: 0.7752 - val_roots_loss: 0.4366 - val_vowels_loss: 0.1979 - val_consonants_loss: 0.1407 - val_roots_acc: 0.8837 - val_vowels_acc: 0.9375 - val_consonants_acc: 0.9594\n",
            "Epoch 24/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.6759 - roots_loss: 0.3527 - vowels_loss: 0.1918 - consonants_loss: 0.1314 - roots_acc: 0.8963 - vowels_acc: 0.9432 - consonants_acc: 0.9599 - val_loss: 0.6662 - val_roots_loss: 0.4126 - val_vowels_loss: 0.1348 - val_consonants_loss: 0.1188 - val_roots_acc: 0.8865 - val_vowels_acc: 0.9651 - val_consonants_acc: 0.9676\n",
            "Epoch 25/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.6479 - roots_loss: 0.3442 - vowels_loss: 0.1808 - consonants_loss: 0.1230 - roots_acc: 0.8980 - vowels_acc: 0.9465 - consonants_acc: 0.9624 - val_loss: 0.7293 - val_roots_loss: 0.4841 - val_vowels_loss: 0.1361 - val_consonants_loss: 0.1092 - val_roots_acc: 0.8678 - val_vowels_acc: 0.9659 - val_consonants_acc: 0.9674\n",
            "Epoch 26/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.6335 - roots_loss: 0.3284 - vowels_loss: 0.1820 - consonants_loss: 0.1231 - roots_acc: 0.9012 - vowels_acc: 0.9462 - consonants_acc: 0.9626 - val_loss: 0.5963 - val_roots_loss: 0.3418 - val_vowels_loss: 0.1515 - val_consonants_loss: 0.1030 - val_roots_acc: 0.9074 - val_vowels_acc: 0.9599 - val_consonants_acc: 0.9706\n",
            "Epoch 27/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.6122 - roots_loss: 0.3163 - vowels_loss: 0.1794 - consonants_loss: 0.1165 - roots_acc: 0.9063 - vowels_acc: 0.9476 - consonants_acc: 0.9649 - val_loss: 0.6062 - val_roots_loss: 0.3792 - val_vowels_loss: 0.1237 - val_consonants_loss: 0.1033 - val_roots_acc: 0.8922 - val_vowels_acc: 0.9699 - val_consonants_acc: 0.9699\n",
            "Epoch 28/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.6044 - roots_loss: 0.3112 - vowels_loss: 0.1740 - consonants_loss: 0.1193 - roots_acc: 0.9083 - vowels_acc: 0.9488 - consonants_acc: 0.9638 - val_loss: 0.5289 - val_roots_loss: 0.2998 - val_vowels_loss: 0.1242 - val_consonants_loss: 0.1049 - val_roots_acc: 0.9169 - val_vowels_acc: 0.9686 - val_consonants_acc: 0.9726\n",
            "Epoch 29/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5870 - roots_loss: 0.3016 - vowels_loss: 0.1728 - consonants_loss: 0.1127 - roots_acc: 0.9121 - vowels_acc: 0.9495 - consonants_acc: 0.9661 - val_loss: 0.6529 - val_roots_loss: 0.4088 - val_vowels_loss: 0.1252 - val_consonants_loss: 0.1188 - val_roots_acc: 0.8875 - val_vowels_acc: 0.9699 - val_consonants_acc: 0.9676\n",
            "Epoch 30/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5792 - roots_loss: 0.2979 - vowels_loss: 0.1683 - consonants_loss: 0.1129 - roots_acc: 0.9122 - vowels_acc: 0.9506 - consonants_acc: 0.9668 - val_loss: 0.5912 - val_roots_loss: 0.3267 - val_vowels_loss: 0.1628 - val_consonants_loss: 0.1017 - val_roots_acc: 0.9089 - val_vowels_acc: 0.9557 - val_consonants_acc: 0.9719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2af2f886f0b04030b15ebe9b2c87201e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training images: (50210, 56, 56, 1)\n",
            "Training labels root: (50210, 168)\n",
            "Training labels vowel: (50210, 11)\n",
            "Training labels consonants: (50210, 7)\n",
            "Epoch 1/30\n",
            "180/180 [==============================] - 110s 609ms/step - loss: 0.8387 - roots_loss: 0.4679 - vowels_loss: 0.2131 - consonants_loss: 0.1578 - roots_acc: 0.8696 - vowels_acc: 0.9392 - consonants_acc: 0.9526 - val_loss: 0.4976 - val_roots_loss: 0.3064 - val_vowels_loss: 0.1049 - val_consonants_loss: 0.0863 - val_roots_acc: 0.9124 - val_vowels_acc: 0.9739 - val_consonants_acc: 0.9766\n",
            "Epoch 2/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.7275 - roots_loss: 0.3961 - vowels_loss: 0.1931 - consonants_loss: 0.1383 - roots_acc: 0.8887 - vowels_acc: 0.9449 - consonants_acc: 0.9575 - val_loss: 0.5801 - val_roots_loss: 0.3471 - val_vowels_loss: 0.1307 - val_consonants_loss: 0.1023 - val_roots_acc: 0.9064 - val_vowels_acc: 0.9661 - val_consonants_acc: 0.9736\n",
            "Epoch 3/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.6918 - roots_loss: 0.3715 - vowels_loss: 0.1881 - consonants_loss: 0.1322 - roots_acc: 0.8942 - vowels_acc: 0.9458 - consonants_acc: 0.9614 - val_loss: 0.6496 - val_roots_loss: 0.3852 - val_vowels_loss: 0.1640 - val_consonants_loss: 0.1004 - val_roots_acc: 0.8962 - val_vowels_acc: 0.9574 - val_consonants_acc: 0.9729\n",
            "Epoch 4/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.6534 - roots_loss: 0.3459 - vowels_loss: 0.1837 - consonants_loss: 0.1238 - roots_acc: 0.9004 - vowels_acc: 0.9478 - consonants_acc: 0.9623 - val_loss: 0.5119 - val_roots_loss: 0.2975 - val_vowels_loss: 0.1187 - val_consonants_loss: 0.0957 - val_roots_acc: 0.9169 - val_vowels_acc: 0.9721 - val_consonants_acc: 0.9721\n",
            "Epoch 5/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.6304 - roots_loss: 0.3325 - vowels_loss: 0.1751 - consonants_loss: 0.1229 - roots_acc: 0.9035 - vowels_acc: 0.9508 - consonants_acc: 0.9633 - val_loss: 0.5224 - val_roots_loss: 0.3051 - val_vowels_loss: 0.1158 - val_consonants_loss: 0.1015 - val_roots_acc: 0.9171 - val_vowels_acc: 0.9731 - val_consonants_acc: 0.9734\n",
            "Epoch 6/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.6090 - roots_loss: 0.3161 - vowels_loss: 0.1747 - consonants_loss: 0.1182 - roots_acc: 0.9086 - vowels_acc: 0.9497 - consonants_acc: 0.9643 - val_loss: 0.4766 - val_roots_loss: 0.2828 - val_vowels_loss: 0.1078 - val_consonants_loss: 0.0859 - val_roots_acc: 0.9228 - val_vowels_acc: 0.9734 - val_consonants_acc: 0.9761\n",
            "Epoch 7/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.5890 - roots_loss: 0.3047 - vowels_loss: 0.1701 - consonants_loss: 0.1142 - roots_acc: 0.9111 - vowels_acc: 0.9507 - consonants_acc: 0.9657 - val_loss: 0.4757 - val_roots_loss: 0.2885 - val_vowels_loss: 0.1148 - val_consonants_loss: 0.0724 - val_roots_acc: 0.9231 - val_vowels_acc: 0.9714 - val_consonants_acc: 0.9813\n",
            "Epoch 8/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5645 - roots_loss: 0.2887 - vowels_loss: 0.1634 - consonants_loss: 0.1125 - roots_acc: 0.9152 - vowels_acc: 0.9539 - consonants_acc: 0.9660 - val_loss: 0.5318 - val_roots_loss: 0.3308 - val_vowels_loss: 0.1120 - val_consonants_loss: 0.0890 - val_roots_acc: 0.9076 - val_vowels_acc: 0.9726 - val_consonants_acc: 0.9754\n",
            "Epoch 9/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.5581 - roots_loss: 0.2834 - vowels_loss: 0.1679 - consonants_loss: 0.1068 - roots_acc: 0.9174 - vowels_acc: 0.9524 - consonants_acc: 0.9678 - val_loss: 0.5050 - val_roots_loss: 0.3159 - val_vowels_loss: 0.1083 - val_consonants_loss: 0.0808 - val_roots_acc: 0.9191 - val_vowels_acc: 0.9736 - val_consonants_acc: 0.9788\n",
            "Epoch 10/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5418 - roots_loss: 0.2746 - vowels_loss: 0.1592 - consonants_loss: 0.1080 - roots_acc: 0.9202 - vowels_acc: 0.9539 - consonants_acc: 0.9673 - val_loss: 0.5264 - val_roots_loss: 0.3404 - val_vowels_loss: 0.0987 - val_consonants_loss: 0.0873 - val_roots_acc: 0.9052 - val_vowels_acc: 0.9749 - val_consonants_acc: 0.9773\n",
            "Epoch 11/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5267 - roots_loss: 0.2662 - vowels_loss: 0.1537 - consonants_loss: 0.1067 - roots_acc: 0.9195 - vowels_acc: 0.9551 - consonants_acc: 0.9690 - val_loss: 0.5142 - val_roots_loss: 0.2989 - val_vowels_loss: 0.1237 - val_consonants_loss: 0.0917 - val_roots_acc: 0.9183 - val_vowels_acc: 0.9701 - val_consonants_acc: 0.9764\n",
            "Epoch 12/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5091 - roots_loss: 0.2568 - vowels_loss: 0.1505 - consonants_loss: 0.1018 - roots_acc: 0.9236 - vowels_acc: 0.9569 - consonants_acc: 0.9694 - val_loss: 0.5481 - val_roots_loss: 0.3407 - val_vowels_loss: 0.1107 - val_consonants_loss: 0.0968 - val_roots_acc: 0.9044 - val_vowels_acc: 0.9729 - val_consonants_acc: 0.9746\n",
            "Epoch 13/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5030 - roots_loss: 0.2549 - vowels_loss: 0.1473 - consonants_loss: 0.1007 - roots_acc: 0.9242 - vowels_acc: 0.9577 - consonants_acc: 0.9702 - val_loss: 0.5193 - val_roots_loss: 0.3252 - val_vowels_loss: 0.1139 - val_consonants_loss: 0.0802 - val_roots_acc: 0.9101 - val_vowels_acc: 0.9696 - val_consonants_acc: 0.9766\n",
            "Epoch 14/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4897 - roots_loss: 0.2456 - vowels_loss: 0.1445 - consonants_loss: 0.0996 - roots_acc: 0.9265 - vowels_acc: 0.9584 - consonants_acc: 0.9705 - val_loss: 0.4956 - val_roots_loss: 0.2889 - val_vowels_loss: 0.1237 - val_consonants_loss: 0.0830 - val_roots_acc: 0.9183 - val_vowels_acc: 0.9691 - val_consonants_acc: 0.9776\n",
            "Epoch 15/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4781 - roots_loss: 0.2363 - vowels_loss: 0.1470 - consonants_loss: 0.0949 - roots_acc: 0.9302 - vowels_acc: 0.9580 - consonants_acc: 0.9709 - val_loss: 0.5114 - val_roots_loss: 0.3073 - val_vowels_loss: 0.1058 - val_consonants_loss: 0.0983 - val_roots_acc: 0.9146 - val_vowels_acc: 0.9739 - val_consonants_acc: 0.9736\n",
            "Epoch 16/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4742 - roots_loss: 0.2352 - vowels_loss: 0.1429 - consonants_loss: 0.0961 - roots_acc: 0.9305 - vowels_acc: 0.9586 - consonants_acc: 0.9720 - val_loss: 0.5276 - val_roots_loss: 0.3263 - val_vowels_loss: 0.1025 - val_consonants_loss: 0.0988 - val_roots_acc: 0.9037 - val_vowels_acc: 0.9751 - val_consonants_acc: 0.9729\n",
            "Epoch 17/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4669 - roots_loss: 0.2310 - vowels_loss: 0.1426 - consonants_loss: 0.0933 - roots_acc: 0.9328 - vowels_acc: 0.9587 - consonants_acc: 0.9719 - val_loss: 0.5010 - val_roots_loss: 0.3186 - val_vowels_loss: 0.0946 - val_consonants_loss: 0.0878 - val_roots_acc: 0.9186 - val_vowels_acc: 0.9776 - val_consonants_acc: 0.9766\n",
            "Epoch 18/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4617 - roots_loss: 0.2239 - vowels_loss: 0.1439 - consonants_loss: 0.0940 - roots_acc: 0.9329 - vowels_acc: 0.9583 - consonants_acc: 0.9722 - val_loss: 0.5340 - val_roots_loss: 0.3265 - val_vowels_loss: 0.1097 - val_consonants_loss: 0.0978 - val_roots_acc: 0.9144 - val_vowels_acc: 0.9798 - val_consonants_acc: 0.9726\n",
            "Epoch 19/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4433 - roots_loss: 0.2237 - vowels_loss: 0.1314 - consonants_loss: 0.0882 - roots_acc: 0.9344 - vowels_acc: 0.9624 - consonants_acc: 0.9738 - val_loss: 0.4586 - val_roots_loss: 0.2818 - val_vowels_loss: 0.0878 - val_consonants_loss: 0.0890 - val_roots_acc: 0.9213 - val_vowels_acc: 0.9798 - val_consonants_acc: 0.9781\n",
            "Epoch 20/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4305 - roots_loss: 0.2082 - vowels_loss: 0.1366 - consonants_loss: 0.0856 - roots_acc: 0.9380 - vowels_acc: 0.9611 - consonants_acc: 0.9742 - val_loss: 0.4900 - val_roots_loss: 0.2952 - val_vowels_loss: 0.1078 - val_consonants_loss: 0.0870 - val_roots_acc: 0.9201 - val_vowels_acc: 0.9756 - val_consonants_acc: 0.9771\n",
            "Epoch 21/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4286 - roots_loss: 0.2117 - vowels_loss: 0.1295 - consonants_loss: 0.0874 - roots_acc: 0.9376 - vowels_acc: 0.9631 - consonants_acc: 0.9739 - val_loss: 0.4930 - val_roots_loss: 0.3050 - val_vowels_loss: 0.1018 - val_consonants_loss: 0.0862 - val_roots_acc: 0.9201 - val_vowels_acc: 0.9766 - val_consonants_acc: 0.9771\n",
            "Epoch 22/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4273 - roots_loss: 0.2069 - vowels_loss: 0.1335 - consonants_loss: 0.0869 - roots_acc: 0.9370 - vowels_acc: 0.9609 - consonants_acc: 0.9741 - val_loss: 0.5140 - val_roots_loss: 0.3170 - val_vowels_loss: 0.1070 - val_consonants_loss: 0.0900 - val_roots_acc: 0.9183 - val_vowels_acc: 0.9761 - val_consonants_acc: 0.9776\n",
            "Epoch 23/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4187 - roots_loss: 0.2024 - vowels_loss: 0.1323 - consonants_loss: 0.0841 - roots_acc: 0.9395 - vowels_acc: 0.9616 - consonants_acc: 0.9747 - val_loss: 0.4730 - val_roots_loss: 0.3074 - val_vowels_loss: 0.0895 - val_consonants_loss: 0.0761 - val_roots_acc: 0.9156 - val_vowels_acc: 0.9818 - val_consonants_acc: 0.9788\n",
            "Epoch 24/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4145 - roots_loss: 0.1982 - vowels_loss: 0.1329 - consonants_loss: 0.0834 - roots_acc: 0.9413 - vowels_acc: 0.9623 - consonants_acc: 0.9753 - val_loss: 0.5052 - val_roots_loss: 0.3175 - val_vowels_loss: 0.1022 - val_consonants_loss: 0.0855 - val_roots_acc: 0.9139 - val_vowels_acc: 0.9764 - val_consonants_acc: 0.9771\n",
            "Epoch 25/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3966 - roots_loss: 0.1926 - vowels_loss: 0.1237 - consonants_loss: 0.0802 - roots_acc: 0.9420 - vowels_acc: 0.9639 - consonants_acc: 0.9759 - val_loss: 0.4685 - val_roots_loss: 0.2806 - val_vowels_loss: 0.1062 - val_consonants_loss: 0.0817 - val_roots_acc: 0.9266 - val_vowels_acc: 0.9773 - val_consonants_acc: 0.9783\n",
            "Epoch 26/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3967 - roots_loss: 0.1919 - vowels_loss: 0.1257 - consonants_loss: 0.0792 - roots_acc: 0.9418 - vowels_acc: 0.9649 - consonants_acc: 0.9760 - val_loss: 0.4739 - val_roots_loss: 0.2829 - val_vowels_loss: 0.1070 - val_consonants_loss: 0.0840 - val_roots_acc: 0.9268 - val_vowels_acc: 0.9776 - val_consonants_acc: 0.9754\n",
            "Epoch 27/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4011 - roots_loss: 0.1931 - vowels_loss: 0.1254 - consonants_loss: 0.0826 - roots_acc: 0.9416 - vowels_acc: 0.9643 - consonants_acc: 0.9757 - val_loss: 0.4440 - val_roots_loss: 0.2668 - val_vowels_loss: 0.0988 - val_consonants_loss: 0.0783 - val_roots_acc: 0.9271 - val_vowels_acc: 0.9778 - val_consonants_acc: 0.9783\n",
            "Epoch 28/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3751 - roots_loss: 0.1801 - vowels_loss: 0.1177 - consonants_loss: 0.0772 - roots_acc: 0.9451 - vowels_acc: 0.9656 - consonants_acc: 0.9766 - val_loss: 0.5293 - val_roots_loss: 0.3276 - val_vowels_loss: 0.1103 - val_consonants_loss: 0.0913 - val_roots_acc: 0.9134 - val_vowels_acc: 0.9734 - val_consonants_acc: 0.9739\n",
            "Epoch 29/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3688 - roots_loss: 0.1751 - vowels_loss: 0.1185 - consonants_loss: 0.0752 - roots_acc: 0.9481 - vowels_acc: 0.9660 - consonants_acc: 0.9783 - val_loss: 0.4297 - val_roots_loss: 0.2497 - val_vowels_loss: 0.0999 - val_consonants_loss: 0.0801 - val_roots_acc: 0.9343 - val_vowels_acc: 0.9783 - val_consonants_acc: 0.9786\n",
            "Epoch 30/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3731 - roots_loss: 0.1780 - vowels_loss: 0.1193 - consonants_loss: 0.0758 - roots_acc: 0.9469 - vowels_acc: 0.9655 - consonants_acc: 0.9776 - val_loss: 0.4696 - val_roots_loss: 0.2945 - val_vowels_loss: 0.1023 - val_consonants_loss: 0.0728 - val_roots_acc: 0.9238 - val_vowels_acc: 0.9759 - val_consonants_acc: 0.9816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "376ab883207a4686bc906b498f4047d5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training images: (50210, 56, 56, 1)\n",
            "Training labels root: (50210, 168)\n",
            "Training labels vowel: (50210, 11)\n",
            "Training labels consonants: (50210, 7)\n",
            "Epoch 1/30\n",
            "180/180 [==============================] - 110s 609ms/step - loss: 0.6659 - roots_loss: 0.3713 - vowels_loss: 0.1711 - consonants_loss: 0.1236 - roots_acc: 0.9002 - vowels_acc: 0.9506 - consonants_acc: 0.9647 - val_loss: 0.5166 - val_roots_loss: 0.3323 - val_vowels_loss: 0.1051 - val_consonants_loss: 0.0792 - val_roots_acc: 0.9096 - val_vowels_acc: 0.9754 - val_consonants_acc: 0.9786\n",
            "Epoch 2/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5764 - roots_loss: 0.3122 - vowels_loss: 0.1546 - consonants_loss: 0.1096 - roots_acc: 0.9122 - vowels_acc: 0.9552 - consonants_acc: 0.9669 - val_loss: 0.4922 - val_roots_loss: 0.2849 - val_vowels_loss: 0.1167 - val_consonants_loss: 0.0907 - val_roots_acc: 0.9263 - val_vowels_acc: 0.9749 - val_consonants_acc: 0.9751\n",
            "Epoch 3/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5467 - roots_loss: 0.2898 - vowels_loss: 0.1536 - consonants_loss: 0.1033 - roots_acc: 0.9183 - vowels_acc: 0.9552 - consonants_acc: 0.9693 - val_loss: 0.4523 - val_roots_loss: 0.2652 - val_vowels_loss: 0.0984 - val_consonants_loss: 0.0887 - val_roots_acc: 0.9293 - val_vowels_acc: 0.9823 - val_consonants_acc: 0.9771\n",
            "Epoch 4/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4990 - roots_loss: 0.2617 - vowels_loss: 0.1394 - consonants_loss: 0.0979 - roots_acc: 0.9250 - vowels_acc: 0.9606 - consonants_acc: 0.9715 - val_loss: 0.4593 - val_roots_loss: 0.2599 - val_vowels_loss: 0.1115 - val_consonants_loss: 0.0880 - val_roots_acc: 0.9360 - val_vowels_acc: 0.9749 - val_consonants_acc: 0.9771\n",
            "Epoch 5/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4733 - roots_loss: 0.2473 - vowels_loss: 0.1329 - consonants_loss: 0.0931 - roots_acc: 0.9267 - vowels_acc: 0.9615 - consonants_acc: 0.9720 - val_loss: 0.4432 - val_roots_loss: 0.2602 - val_vowels_loss: 0.0993 - val_consonants_loss: 0.0837 - val_roots_acc: 0.9310 - val_vowels_acc: 0.9806 - val_consonants_acc: 0.9766\n",
            "Epoch 6/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4580 - roots_loss: 0.2353 - vowels_loss: 0.1345 - consonants_loss: 0.0882 - roots_acc: 0.9316 - vowels_acc: 0.9613 - consonants_acc: 0.9736 - val_loss: 0.4542 - val_roots_loss: 0.2492 - val_vowels_loss: 0.1181 - val_consonants_loss: 0.0870 - val_roots_acc: 0.9373 - val_vowels_acc: 0.9754 - val_consonants_acc: 0.9781\n",
            "Epoch 7/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.4399 - roots_loss: 0.2231 - vowels_loss: 0.1285 - consonants_loss: 0.0883 - roots_acc: 0.9351 - vowels_acc: 0.9635 - consonants_acc: 0.9738 - val_loss: 0.5552 - val_roots_loss: 0.2770 - val_vowels_loss: 0.1940 - val_consonants_loss: 0.0842 - val_roots_acc: 0.9228 - val_vowels_acc: 0.9390 - val_consonants_acc: 0.9768\n",
            "Epoch 8/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.4327 - roots_loss: 0.2184 - vowels_loss: 0.1316 - consonants_loss: 0.0827 - roots_acc: 0.9354 - vowels_acc: 0.9632 - consonants_acc: 0.9755 - val_loss: 0.4347 - val_roots_loss: 0.2594 - val_vowels_loss: 0.0955 - val_consonants_loss: 0.0799 - val_roots_acc: 0.9325 - val_vowels_acc: 0.9808 - val_consonants_acc: 0.9783\n",
            "Epoch 9/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.4201 - roots_loss: 0.2124 - vowels_loss: 0.1258 - consonants_loss: 0.0820 - roots_acc: 0.9385 - vowels_acc: 0.9636 - consonants_acc: 0.9750 - val_loss: 0.5580 - val_roots_loss: 0.2964 - val_vowels_loss: 0.1625 - val_consonants_loss: 0.0992 - val_roots_acc: 0.9183 - val_vowels_acc: 0.9567 - val_consonants_acc: 0.9724\n",
            "Epoch 10/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.4078 - roots_loss: 0.2006 - vowels_loss: 0.1247 - consonants_loss: 0.0825 - roots_acc: 0.9396 - vowels_acc: 0.9653 - consonants_acc: 0.9761 - val_loss: 0.4106 - val_roots_loss: 0.2451 - val_vowels_loss: 0.0903 - val_consonants_loss: 0.0752 - val_roots_acc: 0.9308 - val_vowels_acc: 0.9811 - val_consonants_acc: 0.9806\n",
            "Epoch 11/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3965 - roots_loss: 0.1964 - vowels_loss: 0.1201 - consonants_loss: 0.0800 - roots_acc: 0.9415 - vowels_acc: 0.9655 - consonants_acc: 0.9763 - val_loss: 0.4137 - val_roots_loss: 0.2452 - val_vowels_loss: 0.0897 - val_consonants_loss: 0.0788 - val_roots_acc: 0.9348 - val_vowels_acc: 0.9811 - val_consonants_acc: 0.9786\n",
            "Epoch 12/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3944 - roots_loss: 0.1936 - vowels_loss: 0.1196 - consonants_loss: 0.0812 - roots_acc: 0.9431 - vowels_acc: 0.9653 - consonants_acc: 0.9759 - val_loss: 0.3779 - val_roots_loss: 0.2193 - val_vowels_loss: 0.0865 - val_consonants_loss: 0.0721 - val_roots_acc: 0.9422 - val_vowels_acc: 0.9843 - val_consonants_acc: 0.9813\n",
            "Epoch 13/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3782 - roots_loss: 0.1877 - vowels_loss: 0.1134 - consonants_loss: 0.0770 - roots_acc: 0.9431 - vowels_acc: 0.9674 - consonants_acc: 0.9765 - val_loss: 0.3935 - val_roots_loss: 0.2369 - val_vowels_loss: 0.0800 - val_consonants_loss: 0.0766 - val_roots_acc: 0.9378 - val_vowels_acc: 0.9833 - val_consonants_acc: 0.9783\n",
            "Epoch 14/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3650 - roots_loss: 0.1816 - vowels_loss: 0.1102 - consonants_loss: 0.0731 - roots_acc: 0.9460 - vowels_acc: 0.9678 - consonants_acc: 0.9783 - val_loss: 0.3975 - val_roots_loss: 0.2335 - val_vowels_loss: 0.0958 - val_consonants_loss: 0.0682 - val_roots_acc: 0.9405 - val_vowels_acc: 0.9813 - val_consonants_acc: 0.9823\n",
            "Epoch 15/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3747 - roots_loss: 0.1828 - vowels_loss: 0.1168 - consonants_loss: 0.0750 - roots_acc: 0.9462 - vowels_acc: 0.9668 - consonants_acc: 0.9776 - val_loss: 0.5385 - val_roots_loss: 0.2705 - val_vowels_loss: 0.1752 - val_consonants_loss: 0.0928 - val_roots_acc: 0.9251 - val_vowels_acc: 0.9408 - val_consonants_acc: 0.9773\n",
            "Epoch 16/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3565 - roots_loss: 0.1716 - vowels_loss: 0.1118 - consonants_loss: 0.0731 - roots_acc: 0.9483 - vowels_acc: 0.9672 - consonants_acc: 0.9785 - val_loss: 0.4334 - val_roots_loss: 0.2564 - val_vowels_loss: 0.0896 - val_consonants_loss: 0.0875 - val_roots_acc: 0.9320 - val_vowels_acc: 0.9808 - val_consonants_acc: 0.9751\n",
            "Epoch 17/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.3530 - roots_loss: 0.1714 - vowels_loss: 0.1122 - consonants_loss: 0.0695 - roots_acc: 0.9492 - vowels_acc: 0.9674 - consonants_acc: 0.9794 - val_loss: 0.3950 - val_roots_loss: 0.2138 - val_vowels_loss: 0.1008 - val_consonants_loss: 0.0804 - val_roots_acc: 0.9442 - val_vowels_acc: 0.9803 - val_consonants_acc: 0.9788\n",
            "Epoch 18/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3521 - roots_loss: 0.1700 - vowels_loss: 0.1125 - consonants_loss: 0.0697 - roots_acc: 0.9494 - vowels_acc: 0.9675 - consonants_acc: 0.9794 - val_loss: 0.4428 - val_roots_loss: 0.2793 - val_vowels_loss: 0.0907 - val_consonants_loss: 0.0728 - val_roots_acc: 0.9283 - val_vowels_acc: 0.9808 - val_consonants_acc: 0.9764\n",
            "Epoch 19/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3435 - roots_loss: 0.1645 - vowels_loss: 0.1104 - consonants_loss: 0.0687 - roots_acc: 0.9507 - vowels_acc: 0.9684 - consonants_acc: 0.9796 - val_loss: 0.4051 - val_roots_loss: 0.2336 - val_vowels_loss: 0.0979 - val_consonants_loss: 0.0735 - val_roots_acc: 0.9390 - val_vowels_acc: 0.9818 - val_consonants_acc: 0.9798\n",
            "Epoch 20/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3433 - roots_loss: 0.1600 - vowels_loss: 0.1161 - consonants_loss: 0.0672 - roots_acc: 0.9520 - vowels_acc: 0.9663 - consonants_acc: 0.9799 - val_loss: 0.4097 - val_roots_loss: 0.2393 - val_vowels_loss: 0.0953 - val_consonants_loss: 0.0750 - val_roots_acc: 0.9398 - val_vowels_acc: 0.9818 - val_consonants_acc: 0.9808\n",
            "Epoch 21/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3235 - roots_loss: 0.1543 - vowels_loss: 0.1021 - consonants_loss: 0.0671 - roots_acc: 0.9530 - vowels_acc: 0.9702 - consonants_acc: 0.9804 - val_loss: 0.4396 - val_roots_loss: 0.2537 - val_vowels_loss: 0.1059 - val_consonants_loss: 0.0800 - val_roots_acc: 0.9340 - val_vowels_acc: 0.9756 - val_consonants_acc: 0.9776\n",
            "Epoch 22/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3338 - roots_loss: 0.1584 - vowels_loss: 0.1062 - consonants_loss: 0.0691 - roots_acc: 0.9518 - vowels_acc: 0.9685 - consonants_acc: 0.9789 - val_loss: 0.4455 - val_roots_loss: 0.2513 - val_vowels_loss: 0.1102 - val_consonants_loss: 0.0840 - val_roots_acc: 0.9333 - val_vowels_acc: 0.9744 - val_consonants_acc: 0.9766\n",
            "Epoch 23/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3253 - roots_loss: 0.1547 - vowels_loss: 0.1068 - consonants_loss: 0.0638 - roots_acc: 0.9526 - vowels_acc: 0.9690 - consonants_acc: 0.9810 - val_loss: 0.4335 - val_roots_loss: 0.2612 - val_vowels_loss: 0.0929 - val_consonants_loss: 0.0794 - val_roots_acc: 0.9303 - val_vowels_acc: 0.9823 - val_consonants_acc: 0.9786\n",
            "Epoch 24/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3124 - roots_loss: 0.1450 - vowels_loss: 0.1020 - consonants_loss: 0.0655 - roots_acc: 0.9564 - vowels_acc: 0.9708 - consonants_acc: 0.9801 - val_loss: 0.5618 - val_roots_loss: 0.2779 - val_vowels_loss: 0.1984 - val_consonants_loss: 0.0855 - val_roots_acc: 0.9261 - val_vowels_acc: 0.9373 - val_consonants_acc: 0.9773\n",
            "Epoch 25/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3156 - roots_loss: 0.1470 - vowels_loss: 0.1040 - consonants_loss: 0.0646 - roots_acc: 0.9562 - vowels_acc: 0.9700 - consonants_acc: 0.9808 - val_loss: 0.4086 - val_roots_loss: 0.2593 - val_vowels_loss: 0.0801 - val_consonants_loss: 0.0692 - val_roots_acc: 0.9298 - val_vowels_acc: 0.9828 - val_consonants_acc: 0.9811\n",
            "Epoch 26/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.3169 - roots_loss: 0.1505 - vowels_loss: 0.1011 - consonants_loss: 0.0653 - roots_acc: 0.9549 - vowels_acc: 0.9716 - consonants_acc: 0.9806 - val_loss: 0.4383 - val_roots_loss: 0.2663 - val_vowels_loss: 0.0922 - val_consonants_loss: 0.0799 - val_roots_acc: 0.9266 - val_vowels_acc: 0.9791 - val_consonants_acc: 0.9786\n",
            "Epoch 27/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.3061 - roots_loss: 0.1426 - vowels_loss: 0.1023 - consonants_loss: 0.0611 - roots_acc: 0.9571 - vowels_acc: 0.9699 - consonants_acc: 0.9813 - val_loss: 0.4296 - val_roots_loss: 0.2666 - val_vowels_loss: 0.0906 - val_consonants_loss: 0.0724 - val_roots_acc: 0.9330 - val_vowels_acc: 0.9833 - val_consonants_acc: 0.9821\n",
            "Epoch 28/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.3001 - roots_loss: 0.1390 - vowels_loss: 0.0983 - consonants_loss: 0.0628 - roots_acc: 0.9580 - vowels_acc: 0.9718 - consonants_acc: 0.9803 - val_loss: 0.4085 - val_roots_loss: 0.2471 - val_vowels_loss: 0.0901 - val_consonants_loss: 0.0713 - val_roots_acc: 0.9318 - val_vowels_acc: 0.9811 - val_consonants_acc: 0.9798\n",
            "Epoch 29/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.2967 - roots_loss: 0.1361 - vowels_loss: 0.1003 - consonants_loss: 0.0603 - roots_acc: 0.9581 - vowels_acc: 0.9707 - consonants_acc: 0.9824 - val_loss: 0.3923 - val_roots_loss: 0.2365 - val_vowels_loss: 0.0868 - val_consonants_loss: 0.0690 - val_roots_acc: 0.9363 - val_vowels_acc: 0.9833 - val_consonants_acc: 0.9813\n",
            "Epoch 30/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.2971 - roots_loss: 0.1364 - vowels_loss: 0.1004 - consonants_loss: 0.0603 - roots_acc: 0.9589 - vowels_acc: 0.9698 - consonants_acc: 0.9812 - val_loss: 0.3753 - val_roots_loss: 0.2179 - val_vowels_loss: 0.0829 - val_consonants_loss: 0.0745 - val_roots_acc: 0.9425 - val_vowels_acc: 0.9796 - val_consonants_acc: 0.9806\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbb0d3c3151b42b1b6de36961adc29a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=50210), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Training images: (50210, 56, 56, 1)\n",
            "Training labels root: (50210, 168)\n",
            "Training labels vowel: (50210, 11)\n",
            "Training labels consonants: (50210, 7)\n",
            "Epoch 1/30\n",
            "180/180 [==============================] - 110s 610ms/step - loss: 0.6008 - roots_loss: 0.3399 - vowels_loss: 0.1526 - consonants_loss: 0.1084 - roots_acc: 0.9095 - vowels_acc: 0.9564 - consonants_acc: 0.9685 - val_loss: 0.4877 - val_roots_loss: 0.3238 - val_vowels_loss: 0.0850 - val_consonants_loss: 0.0789 - val_roots_acc: 0.9124 - val_vowels_acc: 0.9816 - val_consonants_acc: 0.9813\n",
            "Epoch 2/30\n",
            "180/180 [==============================] - 109s 606ms/step - loss: 0.5072 - roots_loss: 0.2746 - vowels_loss: 0.1340 - consonants_loss: 0.0985 - roots_acc: 0.9233 - vowels_acc: 0.9616 - consonants_acc: 0.9708 - val_loss: 0.7108 - val_roots_loss: 0.2659 - val_vowels_loss: 0.3657 - val_consonants_loss: 0.0792 - val_roots_acc: 0.9295 - val_vowels_acc: 0.8476 - val_consonants_acc: 0.9813\n",
            "Epoch 3/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.4634 - roots_loss: 0.2438 - vowels_loss: 0.1284 - consonants_loss: 0.0913 - roots_acc: 0.9303 - vowels_acc: 0.9630 - consonants_acc: 0.9726 - val_loss: 0.4214 - val_roots_loss: 0.2478 - val_vowels_loss: 0.0962 - val_consonants_loss: 0.0774 - val_roots_acc: 0.9330 - val_vowels_acc: 0.9846 - val_consonants_acc: 0.9823\n",
            "Epoch 4/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.4467 - roots_loss: 0.2379 - vowels_loss: 0.1229 - consonants_loss: 0.0859 - roots_acc: 0.9326 - vowels_acc: 0.9647 - consonants_acc: 0.9750 - val_loss: 0.4345 - val_roots_loss: 0.2438 - val_vowels_loss: 0.1097 - val_consonants_loss: 0.0809 - val_roots_acc: 0.9390 - val_vowels_acc: 0.9851 - val_consonants_acc: 0.9841\n",
            "Epoch 5/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.4135 - roots_loss: 0.2121 - vowels_loss: 0.1220 - consonants_loss: 0.0795 - roots_acc: 0.9379 - vowels_acc: 0.9651 - consonants_acc: 0.9771 - val_loss: 0.4341 - val_roots_loss: 0.2572 - val_vowels_loss: 0.1018 - val_consonants_loss: 0.0751 - val_roots_acc: 0.9335 - val_vowels_acc: 0.9831 - val_consonants_acc: 0.9848\n",
            "Epoch 6/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.4035 - roots_loss: 0.2057 - vowels_loss: 0.1194 - consonants_loss: 0.0785 - roots_acc: 0.9407 - vowels_acc: 0.9658 - consonants_acc: 0.9769 - val_loss: 0.4301 - val_roots_loss: 0.2512 - val_vowels_loss: 0.1049 - val_consonants_loss: 0.0740 - val_roots_acc: 0.9365 - val_vowels_acc: 0.9808 - val_consonants_acc: 0.9843\n",
            "Epoch 7/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3938 - roots_loss: 0.2019 - vowels_loss: 0.1169 - consonants_loss: 0.0750 - roots_acc: 0.9413 - vowels_acc: 0.9658 - consonants_acc: 0.9784 - val_loss: 0.4008 - val_roots_loss: 0.2356 - val_vowels_loss: 0.0955 - val_consonants_loss: 0.0698 - val_roots_acc: 0.9393 - val_vowels_acc: 0.9818 - val_consonants_acc: 0.9801\n",
            "Epoch 8/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.3651 - roots_loss: 0.1856 - vowels_loss: 0.1070 - consonants_loss: 0.0725 - roots_acc: 0.9455 - vowels_acc: 0.9688 - consonants_acc: 0.9782 - val_loss: 0.3843 - val_roots_loss: 0.2341 - val_vowels_loss: 0.0770 - val_consonants_loss: 0.0733 - val_roots_acc: 0.9425 - val_vowels_acc: 0.9885 - val_consonants_acc: 0.9823\n",
            "Epoch 9/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3658 - roots_loss: 0.1806 - vowels_loss: 0.1125 - consonants_loss: 0.0727 - roots_acc: 0.9466 - vowels_acc: 0.9671 - consonants_acc: 0.9790 - val_loss: 0.3985 - val_roots_loss: 0.2393 - val_vowels_loss: 0.0917 - val_consonants_loss: 0.0675 - val_roots_acc: 0.9378 - val_vowels_acc: 0.9823 - val_consonants_acc: 0.9846\n",
            "Epoch 10/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3553 - roots_loss: 0.1748 - vowels_loss: 0.1089 - consonants_loss: 0.0715 - roots_acc: 0.9487 - vowels_acc: 0.9682 - consonants_acc: 0.9791 - val_loss: 0.4029 - val_roots_loss: 0.2418 - val_vowels_loss: 0.0929 - val_consonants_loss: 0.0683 - val_roots_acc: 0.9368 - val_vowels_acc: 0.9793 - val_consonants_acc: 0.9851\n",
            "Epoch 11/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3410 - roots_loss: 0.1655 - vowels_loss: 0.1074 - consonants_loss: 0.0681 - roots_acc: 0.9514 - vowels_acc: 0.9690 - consonants_acc: 0.9798 - val_loss: 0.3659 - val_roots_loss: 0.2157 - val_vowels_loss: 0.0825 - val_consonants_loss: 0.0676 - val_roots_acc: 0.9420 - val_vowels_acc: 0.9823 - val_consonants_acc: 0.9836\n",
            "Epoch 12/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3352 - roots_loss: 0.1644 - vowels_loss: 0.1042 - consonants_loss: 0.0666 - roots_acc: 0.9505 - vowels_acc: 0.9692 - consonants_acc: 0.9805 - val_loss: 0.4085 - val_roots_loss: 0.2452 - val_vowels_loss: 0.0913 - val_consonants_loss: 0.0719 - val_roots_acc: 0.9345 - val_vowels_acc: 0.9823 - val_consonants_acc: 0.9828\n",
            "Epoch 13/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3265 - roots_loss: 0.1590 - vowels_loss: 0.0987 - consonants_loss: 0.0688 - roots_acc: 0.9518 - vowels_acc: 0.9712 - consonants_acc: 0.9801 - val_loss: 0.3974 - val_roots_loss: 0.2410 - val_vowels_loss: 0.0782 - val_consonants_loss: 0.0782 - val_roots_acc: 0.9368 - val_vowels_acc: 0.9838 - val_consonants_acc: 0.9808\n",
            "Epoch 14/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3258 - roots_loss: 0.1575 - vowels_loss: 0.1000 - consonants_loss: 0.0682 - roots_acc: 0.9535 - vowels_acc: 0.9698 - consonants_acc: 0.9795 - val_loss: 0.3832 - val_roots_loss: 0.2142 - val_vowels_loss: 0.0921 - val_consonants_loss: 0.0769 - val_roots_acc: 0.9437 - val_vowels_acc: 0.9803 - val_consonants_acc: 0.9818\n",
            "Epoch 15/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.3202 - roots_loss: 0.1562 - vowels_loss: 0.1006 - consonants_loss: 0.0634 - roots_acc: 0.9539 - vowels_acc: 0.9705 - consonants_acc: 0.9815 - val_loss: 0.3855 - val_roots_loss: 0.2360 - val_vowels_loss: 0.0879 - val_consonants_loss: 0.0616 - val_roots_acc: 0.9365 - val_vowels_acc: 0.9838 - val_consonants_acc: 0.9868\n",
            "Epoch 16/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3197 - roots_loss: 0.1509 - vowels_loss: 0.1031 - consonants_loss: 0.0657 - roots_acc: 0.9550 - vowels_acc: 0.9699 - consonants_acc: 0.9809 - val_loss: 0.3707 - val_roots_loss: 0.2241 - val_vowels_loss: 0.0809 - val_consonants_loss: 0.0657 - val_roots_acc: 0.9417 - val_vowels_acc: 0.9838 - val_consonants_acc: 0.9848\n",
            "Epoch 17/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3043 - roots_loss: 0.1433 - vowels_loss: 0.0995 - consonants_loss: 0.0614 - roots_acc: 0.9567 - vowels_acc: 0.9700 - consonants_acc: 0.9816 - val_loss: 0.4415 - val_roots_loss: 0.2382 - val_vowels_loss: 0.1294 - val_consonants_loss: 0.0739 - val_roots_acc: 0.9345 - val_vowels_acc: 0.9651 - val_consonants_acc: 0.9808\n",
            "Epoch 18/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.3029 - roots_loss: 0.1413 - vowels_loss: 0.0992 - consonants_loss: 0.0625 - roots_acc: 0.9576 - vowels_acc: 0.9709 - consonants_acc: 0.9820 - val_loss: 0.3959 - val_roots_loss: 0.2385 - val_vowels_loss: 0.0835 - val_consonants_loss: 0.0740 - val_roots_acc: 0.9373 - val_vowels_acc: 0.9828 - val_consonants_acc: 0.9836\n",
            "Epoch 19/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2983 - roots_loss: 0.1386 - vowels_loss: 0.0983 - consonants_loss: 0.0614 - roots_acc: 0.9588 - vowels_acc: 0.9719 - consonants_acc: 0.9824 - val_loss: 0.4269 - val_roots_loss: 0.2570 - val_vowels_loss: 0.0976 - val_consonants_loss: 0.0723 - val_roots_acc: 0.9340 - val_vowels_acc: 0.9781 - val_consonants_acc: 0.9821\n",
            "Epoch 20/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.2905 - roots_loss: 0.1396 - vowels_loss: 0.0919 - consonants_loss: 0.0590 - roots_acc: 0.9587 - vowels_acc: 0.9724 - consonants_acc: 0.9822 - val_loss: 0.4065 - val_roots_loss: 0.2490 - val_vowels_loss: 0.0888 - val_consonants_loss: 0.0687 - val_roots_acc: 0.9330 - val_vowels_acc: 0.9801 - val_consonants_acc: 0.9833\n",
            "Epoch 21/30\n",
            "180/180 [==============================] - 109s 607ms/step - loss: 0.2933 - roots_loss: 0.1373 - vowels_loss: 0.0958 - consonants_loss: 0.0602 - roots_acc: 0.9601 - vowels_acc: 0.9720 - consonants_acc: 0.9823 - val_loss: 0.4044 - val_roots_loss: 0.2358 - val_vowels_loss: 0.0987 - val_consonants_loss: 0.0699 - val_roots_acc: 0.9380 - val_vowels_acc: 0.9791 - val_consonants_acc: 0.9826\n",
            "Epoch 22/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2910 - roots_loss: 0.1368 - vowels_loss: 0.0965 - consonants_loss: 0.0577 - roots_acc: 0.9586 - vowels_acc: 0.9713 - consonants_acc: 0.9825 - val_loss: 0.3671 - val_roots_loss: 0.2313 - val_vowels_loss: 0.0689 - val_consonants_loss: 0.0668 - val_roots_acc: 0.9375 - val_vowels_acc: 0.9853 - val_consonants_acc: 0.9826\n",
            "Epoch 23/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2828 - roots_loss: 0.1335 - vowels_loss: 0.0913 - consonants_loss: 0.0580 - roots_acc: 0.9599 - vowels_acc: 0.9735 - consonants_acc: 0.9834 - val_loss: 0.4014 - val_roots_loss: 0.2580 - val_vowels_loss: 0.0751 - val_consonants_loss: 0.0682 - val_roots_acc: 0.9328 - val_vowels_acc: 0.9878 - val_consonants_acc: 0.9826\n",
            "Epoch 24/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2784 - roots_loss: 0.1287 - vowels_loss: 0.0910 - consonants_loss: 0.0587 - roots_acc: 0.9608 - vowels_acc: 0.9728 - consonants_acc: 0.9829 - val_loss: 0.4044 - val_roots_loss: 0.2389 - val_vowels_loss: 0.0993 - val_consonants_loss: 0.0662 - val_roots_acc: 0.9368 - val_vowels_acc: 0.9773 - val_consonants_acc: 0.9853\n",
            "Epoch 25/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2678 - roots_loss: 0.1245 - vowels_loss: 0.0863 - consonants_loss: 0.0570 - roots_acc: 0.9626 - vowels_acc: 0.9744 - consonants_acc: 0.9832 - val_loss: 0.4019 - val_roots_loss: 0.2464 - val_vowels_loss: 0.0921 - val_consonants_loss: 0.0634 - val_roots_acc: 0.9353 - val_vowels_acc: 0.9831 - val_consonants_acc: 0.9846\n",
            "Epoch 26/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2719 - roots_loss: 0.1296 - vowels_loss: 0.0874 - consonants_loss: 0.0548 - roots_acc: 0.9617 - vowels_acc: 0.9738 - consonants_acc: 0.9842 - val_loss: 0.3563 - val_roots_loss: 0.2179 - val_vowels_loss: 0.0781 - val_consonants_loss: 0.0603 - val_roots_acc: 0.9427 - val_vowels_acc: 0.9841 - val_consonants_acc: 0.9851\n",
            "Epoch 27/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2616 - roots_loss: 0.1227 - vowels_loss: 0.0862 - consonants_loss: 0.0527 - roots_acc: 0.9630 - vowels_acc: 0.9747 - consonants_acc: 0.9840 - val_loss: 0.3911 - val_roots_loss: 0.2312 - val_vowels_loss: 0.0960 - val_consonants_loss: 0.0640 - val_roots_acc: 0.9365 - val_vowels_acc: 0.9783 - val_consonants_acc: 0.9848\n",
            "Epoch 28/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2692 - roots_loss: 0.1224 - vowels_loss: 0.0917 - consonants_loss: 0.0552 - roots_acc: 0.9629 - vowels_acc: 0.9729 - consonants_acc: 0.9840 - val_loss: 0.3909 - val_roots_loss: 0.2293 - val_vowels_loss: 0.0961 - val_consonants_loss: 0.0655 - val_roots_acc: 0.9378 - val_vowels_acc: 0.9756 - val_consonants_acc: 0.9821\n",
            "Epoch 29/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2603 - roots_loss: 0.1182 - vowels_loss: 0.0859 - consonants_loss: 0.0562 - roots_acc: 0.9639 - vowels_acc: 0.9751 - consonants_acc: 0.9838 - val_loss: 0.3869 - val_roots_loss: 0.2322 - val_vowels_loss: 0.0816 - val_consonants_loss: 0.0731 - val_roots_acc: 0.9380 - val_vowels_acc: 0.9843 - val_consonants_acc: 0.9836\n",
            "Epoch 30/30\n",
            "180/180 [==============================] - 109s 608ms/step - loss: 0.2596 - roots_loss: 0.1212 - vowels_loss: 0.0847 - consonants_loss: 0.0536 - roots_acc: 0.9631 - vowels_acc: 0.9749 - consonants_acc: 0.9845 - val_loss: 0.4001 - val_roots_loss: 0.2402 - val_vowels_loss: 0.0895 - val_consonants_loss: 0.0703 - val_roots_acc: 0.9405 - val_vowels_acc: 0.9796 - val_consonants_acc: 0.9833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRg6hzVYlP6J",
        "colab_type": "code",
        "outputId": "a3dd48a3-db36-453b-d13a-628f9dbf0f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "model_name = 'FractalNet_Model_0302.h5'\n",
        "save_dir = os.path.join(\"drive/My Drive/Neural NotWork/\", 'saved_models')\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at drive/My Drive/Neural NotWork/saved_models/FractalNet_Model_0302.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrGVFFytmdjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}